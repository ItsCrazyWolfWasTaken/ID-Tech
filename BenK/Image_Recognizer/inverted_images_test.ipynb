{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBa8UUaPrgaR"
   },
   "source": [
    "# Intro to Convolutional Neural Networks\n",
    "\n",
    "So far you have been working with fully connected, or densely connected networks. These networks work well for extremely well-defined problems, like with the MNIST dataset, but it isn't very good at extracting more general information about a picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "53zaUfyyrZak"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the image library from keras.preprocessing.\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Import the Image and ImageChops library from the pillow library.\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "# Import TensorFlow and Keras to create the neural network.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Import the MNIST dataset and backend as K.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Import NumPy and Matplotlib libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pM8rm5C9B9B"
   },
   "source": [
    "# Testing your Network\n",
    "Now that you've imported and setup the libraries, you'll test your densely connected network by loading the MNIST data and printing the network's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-MZB5J22ZlA"
   },
   "source": [
    "## Load the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u-ZMxu-k2c1q"
   },
   "outputs": [],
   "source": [
    "# Load the MNIST Data\n",
    "def show_min_max(array, i):\n",
    "    random_image = array[i]\n",
    "    print(random_image.min(), random_image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G4pbttWj2ynP"
   },
   "outputs": [],
   "source": [
    "# Create a function that will plot a image from the dataset and display the image.\n",
    "def plot_image(array, i, labels):\n",
    "    plt.imshow(np. squeeze (array[i]))\n",
    "    plt.title(\" Digit \" + str(labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qIqEGcBC3CQ2"
   },
   "outputs": [],
   "source": [
    "# Create a function called predict_image that will print the densely connected network's prediction for the image.\n",
    "def predict_image (model, x):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    \n",
    "    x = np.expand_dims (x, axis=0)\n",
    "    \n",
    "    image_predict = model.predict(x, verbose=0) \n",
    "    print(\"Predicted Label: \", np.argmax(image_predict))\n",
    "    \n",
    "    plt.imshow(np.squeeze(x))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) \n",
    "    plt.show()\n",
    "    return image_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "khJAKF2R3xsU"
   },
   "outputs": [],
   "source": [
    "# Create a function called plot_value_array that will plot the image and predicted value.\n",
    "def plot_value_array(predictions_array, true_label, h):\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array[0], color=\"#777777\")\n",
    "    plt.ylim([(-1*h), h])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    thisplot [predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MLY1MPHw6KBk"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at my_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the 'my_model.h5'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmy_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    264\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         )\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    241\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at my_model.h5"
     ]
    }
   ],
   "source": [
    "# Load the 'my_model.h5'\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMIjUUqylMSE"
   },
   "source": [
    "## Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4trq1UsnWXA"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess a test image for the network.\n",
    "path = \"invertedTest.jpg\"\n",
    "img = tf.keras.preprocessing.image.load_img(path, target_size=(28,28), color_mode = \"grayscale\")\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mo0gjebcnlPz"
   },
   "outputs": [],
   "source": [
    "# Run the densely connected network to see its prediction for the image.\n",
    "true_label = 3\n",
    "p_arr = predict_image(model, x)\n",
    "plot_value_array(p_arr, true_label, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXP3wsWCny1i"
   },
   "outputs": [],
   "source": [
    "# Re-run the network to see the colors inverted.\n",
    "x_inv = 255-x\n",
    "arr = predict_image(model, x_inv)\n",
    "plot_value_array(arr, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAn0fNghn6VQ"
   },
   "source": [
    "# Data Preparation and Fixing the Flaws\n",
    "The network can correctly predict images, but only in a very specific set of parameters. Since all of the training images are white drawings with black backgrounds, when the network tries to guess what an image with a white background is, it has a much harder time making conclusions.\n",
    "\n",
    "For the next part, you'll invert *some* of the training data so that the network is able to practice on both white backgrounds and black backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKR-ToDfqVOM"
   },
   "outputs": [],
   "source": [
    "# Create variables to keep track of the number rows and columns for each image.\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVY0eg1fqZwj"
   },
   "outputs": [],
   "source": [
    "# Create a variable to keep track of the number of output classes.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqGw18oIqbrE"
   },
   "outputs": [],
   "source": [
    "# Load the train and test data, and a backup of each.\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "(train_images_backup, train_labels_backup), (test_images_backup, test_labels_backup) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N0eqBdVqdhr"
   },
   "outputs": [],
   "source": [
    "# Print the shape to confirm it's the right data.\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k96xjsCMqgUW"
   },
   "outputs": [],
   "source": [
    "# Reshape the training and test data by converting the list of pixels into a 28x28 grid.\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QxUJMq7qhyE"
   },
   "outputs": [],
   "source": [
    "# Create an input_shape variable to keep track of the data's shape.\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__-rpkj4qklD"
   },
   "outputs": [],
   "source": [
    "# Call the plot_image function to print out the 3001 image in train_images.\n",
    "plot_image(train_images, 30001, train_labels)\n",
    "# Call the show_min_max function to display the min and max values of the image. \n",
    "show_min_max(train_images, 30001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNyG8pD7n7Cq"
   },
   "outputs": [],
   "source": [
    "# Invert the training data for the network to practice on white backgrounds and black backgrounds.\n",
    "train_images[30000:]=255-train_images[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HW9DQNVAqyj2"
   },
   "outputs": [],
   "source": [
    "# Change the image values to between 0 and 1, convert that training and test data into float32.\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EPZ8Q9Qq07S"
   },
   "outputs": [],
   "source": [
    "# Divide the images by 255 to make sure that each pixel is stored as a value between 0 and 1.\n",
    "train_images /= 255\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgfxsY4bq2q7"
   },
   "outputs": [],
   "source": [
    "# With the adjusted data, call the plot_image function to print out the 3001 image in train_images.\n",
    "plot_image(train_images, 30001, train_labels)\n",
    "# with the adjusted data, call the show_min_max function to display the min and max values of the image. \n",
    "show_min_max(train_images, 30001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7HFxxjrrA10"
   },
   "outputs": [],
   "source": [
    "# Employ one-hot encoding on your training labels.\n",
    "train_labels = keras.utils.to_categorical (train_labels, num_classes)\n",
    "#Employ one-hot encoding on your test labels.\n",
    "test_labels = keras.utils.to_categorical (test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSO_sOCTrJdM"
   },
   "source": [
    "# Re-training the Network\n",
    "Now that you've prepared your data again and fixed the flaws, you'll re-train your network by importing the sequential model and adding the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnmkUZwvt9fl"
   },
   "source": [
    "## Import Model and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrsgaisNrOMG"
   },
   "outputs": [],
   "source": [
    "# Import the Sequential model.\n",
    "from tensorflow.keras.models import Sequential\n",
    "#Import the Dense and Flatten layers.\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUr_ClSWuBNS"
   },
   "outputs": [],
   "source": [
    "# Create a variable called epochs and set the value as 10.\n",
    "epochs = 10\n",
    "# Create a new model object called model_inv using the Keras Sequential command. \n",
    "model_inv = Sequential()\n",
    "# Add a Flatten layer and pass the input shape as an argument.\n",
    "model_inv.add(Flatten(input_shape=input_shape))\n",
    "# Add a Dense layer to your network with the size of the layers in neurons and relu as the activation function. \n",
    "model_inv.add(Dense(16, activation='relu'))\n",
    "# Add an output layer\n",
    "model_inv.add(Dense(10, activation='softmax'))\n",
    "# Print a summary of your network so far. \n",
    "model_inv.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtyz1UzjvJh9"
   },
   "source": [
    "## Compile the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIA4ro36veUh"
   },
   "outputs": [],
   "source": [
    "# Add the compile function that calculates the loss and uses the optimizer parameter to set the optimization algorithm.\n",
    "model_inv.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mex912gAv6AU"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2EzYVSXv8xv"
   },
   "outputs": [],
   "source": [
    "# Add the fit function and set the input data for this model so the network doesn't rely on a pattern to learn.\n",
    "model_inv.fit(train_images, train_labels, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5xpiKzXwI7c"
   },
   "source": [
    "## Analyzing the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvFKwRhTwJpY"
   },
   "outputs": [],
   "source": [
    "# Calculate the loss and accuracy of your model.\n",
    "test_loss, test_acc = model_inv.evaluate(test_images, test_labels, verbose=2)\n",
    "# Print out the test accuracy.\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3D7yVDjwl5b"
   },
   "source": [
    "# Testing your Network\n",
    "With your network trained, you'll test the network and print a graph and a list with the predicted ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2CP_BPlwr56"
   },
   "outputs": [],
   "source": [
    "# Create a variable called arr to hold the network's predicted value.\n",
    "arr = predict_image(model_inv, x)\n",
    "\n",
    "# Plot the predicted values to a graph.\n",
    "plot_value_array(arr, 3, 1)\n",
    "\n",
    "# Print the list with the predicted values.\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCaj3IcuwXtu"
   },
   "source": [
    "# Exporting your Model\n",
    "Finally, you'll export your model and save it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wh_vewmbwYm8"
   },
   "outputs": [],
   "source": [
    "# Export your model.\n",
    "model_inv.save('my_model_inv.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
